{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Agricultural Bird Pest Control: Utilizing Computer Vision for Pest Management\n",
    "\n",
    "## Abstract\n",
    "This project focuses on developing a smart bird detection and repellent system aimed at protecting agricultural fields from bird-related crop damage. By leveraging computer vision and sound-based repellent mechanisms, the system will detect birds and trigger distress calls or ultrasonic sounds to scare them away. The solution is designed to be cost-effective, environmentally friendly, and sustainable, reducing the reliance on harmful methods like chemicals or physical barriers. The project begins by collecting a large dataset of bird images using web scraping techniques, which will be used to train the detection model. The project will then evolve to involve the integration of IoT systems for real-time monitoring and automated responses using Raspberry Pi.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Overview](#overview)\n",
    "2. [Data Sources](#data-sources)\n",
    "3. [Importing Libraries](#importing-libraries)\n",
    "4. [Data Collection](#data-collection)\n",
    "5. [Exploratory Data Analysis (EDA)](#exploratory-data-analysis-eda)\n",
    "6. [Data Preprocessing](#data-preprocessing)\n",
    "7. [Model Development](#model-development)\n",
    "8. [Results and Evaluation](#results-and-evaluation)\n",
    "9. [Conclusion and Next Steps](#conclusion-and-next-steps)\n",
    "10. [References](#references)\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Problem Statement\n",
    "Birds can cause significant damage to agricultural fields, threatening crop yields and food security worldwide. This problem is best illustrated by the 2023 invasion of red-billed quelea birds in Kenya, where farmers may lose up to 60 tonnes of grain as a result of these pests. This situation is worsened by ongoing drought conditions in the Horn of Africa, which have driven quelea to invade cultivated fields in search of food. In fact, the Food and Agricultural Organization (FAO) estimates that such crop losses amount to $50 million annually across sub-Saharan Africa.\n",
    "\n",
    "The Kenyan government’s response to this issue has included the controversial use of toxic pesticides like fenthion to eradicate quelea populations. While intended to protect crops, this approach raises serious environmental and health concerns, as the indiscriminate nature of these chemicals poses risks to non-target wildlife, particularly endangered raptors, and can lead to ecological imbalances. Furthermore, the rapid breeding capabilities of birds, coupled with their consumption of up to 10 grams of grain daily, highlight the urgent need for sustainable and effective solutions to mitigate the impacts of avian pests on agriculture.\n",
    "\n",
    "This project seeks to address the broader issue of bird-related crop damage by developing a smart bird detection and repellent system that leverages computer vision and sound-based mechanisms. The system will detect birds and trigger distress calls or ultrasonic sounds to deter them, providing a cost-effective and environmentally friendly alternative to harmful pesticides. The initial phase will involve collecting a comprehensive dataset of bird images through web scraping, which will be utilized to train the detection model. The project will later on evolve to incorporate IoT systems for real-time monitoring and automated responses using Raspberry Pi, empowering farmers to protect their crops while promoting ecological sustainability.\n",
    "\n",
    "The following sections will detail the data sources, methods, and results of this project, highlighting the significance of technology in modern pest control and its potential impact on agricultural sustainability.\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "The projectutilised data from various sources which was collected using various methods such as web scraping.\n",
    "\n",
    "[African Bird Club](https://www.africanbirdclub.org/)\n",
    "\n",
    "## Importing Libraries\n",
    "\n",
    "Below are all the libraries that shall be used for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "### Web Scraping\n",
    "#### African Bird Club\n",
    "The first data collected was from [African Bird Club](https://www.africanbirdclub.org/). In this section, I shall download and store 2,334 bird images of 673 Kenyan bird species through web scraping using beautiful soup.\n",
    "\n",
    "The first thing I did was set the links to the [website](https://www.africanbirdclub.org/) that we would be accessing information from. I separated the two links to keep the code clean and flexible since I shall be collecting information from different pages. \n",
    "- The `base_url` holds the main address of the site and serves as the foundation for any additional links on the site\n",
    "- `species_info_url` contains the path to the page with the kkenyan bird species information. \n",
    "\n",
    "This approach makes it easier to update or reuse parts of the URL later on if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the links to the pages to retrieve information from\n",
    "base_url = 'https://www.africanbirdclub.org'\n",
    "species_info_url = f'{base_url}/afbid/search/category/-/-/28'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When scraping data from websites, it’s important to identify your request as coming from a legitimate source, such as a web browser rather than a bot or scraper, so as to allow one to retrieve the necessary data smoothly. Websites can block requests if they think the traffic isn’t from a real user. To avoid this, we need to set headers that make the requests look like they're coming from a browser. \n",
    "\n",
    "I set the headers to include a `User-Agent`. You can find more information about `User-Agent` in [User-Agent Documentation](https://pypi.org/project/user-agents/), which is a string used by web browsers to identify themselves when making requests to websites. By using this, we ensure that the website allows our code to access the information without blocking it. In this case, I used a User-Agent that mimics a standard Chrome browser on Windows.\n",
    "\n",
    "To understand more about why headers are important you can read [this article.](https://www.zenrows.com/blog/python-requests-user-agent#what-is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set headers with a User-Agent to allow access\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting the header, I sent a request using the `requests.get` method, which sends a GET request to the `species_info_url`, containing the specific endpoint for the bird species information. I also include the headers  defined earlier to ensure the request is accepted. You can find more details about the requests.get method in the [Requests Documentation](https://pypi.org/project/requests/).\n",
    "\n",
    "After sending the request, I checked the status code of the response to determine if the request was successful. A status code of 200 indicates that the request was successful and the page has been successfully retrieved. If a different status code is recieved, a message to inform of the failure is printed, including the specific status code received. This helps in easier identifying and troubleshooting any issues with the request.\n",
    "\n",
    "If the request is successful, the HTML content of the response is parsed using BeautifulSoup. BeautifulSoup is a powerful library for parsing HTML and XML documents, as detailed in the [documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/). By passing the content of the response and specifying the parser ('html.parser'), a soup object is created, which allows for easy navigation and extraction of data from the HTML structure of the page.\n",
    "\n",
    "This step is crucial, as it lays the foundation for extracting the necessary information about the bird species from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the species list page\n",
    "response_info = requests.get(species_info_url, headers=headers)\n",
    "if response_info.status_code != 200:\n",
    "    print(f\"Failed to retrieve species list page, status code: {response_info.status_code}\")\n",
    "else:\n",
    "    soup_info = BeautifulSoup(response_info.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, the HTML structure of the page is assessed. It can be noted that the structure is such that the bird species are arranged in a list contained in the class`inner-panel` as shown below:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"images-used/species-info-page-html.png\" alt=\" Species information pageand HTML structure\" style=\"width: 800px; height: auto;\">\n",
    "</div>\n",
    "           \n",
    "From this page, information on the bird's `species_name`, `common_name`, and the `img_link` will be scraped and stored. The aim is to locate the specific elements within the HTML document of the `species_info_url` page that contain the list of bird species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the div and ul containing the species list\n",
    "species_div = soup_info.find('div', class_='panel-inner')  # Find the div with class \"panel-inner\"\n",
    "species_list = species_div.find('ul', class_='type')  # Find the ul with class \"type\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line uses the find method of BeautifulSoup to search for a `<div>` tag that has the class attribute of panel-inner which is the container for the species list.\n",
    "\n",
    "The second line searches for an `<ul>` tag (unordered list) within the previously identified species_div. The class of this `<ul>` is type, which indicates that it holds the list of bird species. By extracting this `<ul>`, we can access all the individual list items `<li>` that contain the species names and other relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Species: Acrocephalus arundinaceus (1), Common Name: Great Reed Warbler, Image Link: /afbid/search/browse/species/1503/28\n"
     ]
    }
   ],
   "source": [
    " # Find all species items (li elements)\n",
    "species_items = species_list.find_all('li')\n",
    "\n",
    "# Use indexing to pick the species you want (e.g., the first species)\n",
    "selected_species = species_items[0]  # Indexing to select the first species (change index as needed)\n",
    "image_link = selected_species.find('a')['href']  # Get the link from the <a> tag\n",
    "species_name = selected_species.find('h5').text.strip()  # Get the species name\n",
    "common_name = selected_species.find('span').text.strip()  # Get the common name\n",
    "\n",
    "print(f\"Selected Species: {species_name}, Common Name: {common_name}, Image Link: {image_link}\")\n",
    "\n",
    "# Add sleep time to avoid overwhelming the server\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
